#!/usr/bin/env python3
import datetime
import hashlib
import os
import re
import subprocess
import sys

# This script only modifies SRCS and VER.
keys_to_modify = ['VER', 'SRCS']

# REL will be removed.
keys_to_skip = ['REL']

class logger:
	DEBUG = 1
	INFO = 2
	WARN = 3
	ERR = 4
	QUIET = 5

	level: int = INFO

	@staticmethod
	def out(string, level):
		if level >= logger.level:
			print("nightly-checker> " + string)

	@staticmethod
	def debug(string: str):
		logger.out(string, logger.DEBUG)

	@staticmethod
	def info(string: str):
		logger.out(string, logger.INFO)

	@staticmethod
	def warn(string: str):
		logger.out(string, logger.WARN)

	@staticmethod
	def error(string: str):
		logger.out(string, logger.ERR)


def parse_kvs(content: list[str]) -> dict:
	lastline = ''
	parsed_lines = []
	kvs: dict[str, str] = {}
	for line in content:
		logger.debug('Current line: {}'.format(line))
		if len(line.strip()) == 0:
			continue
		lastline = ' '.join([lastline.rstrip().rstrip('\\'), line]).lstrip()
		if not line.rstrip().endswith('\\'):
			logger.debug('Appending line: {}'.format(lastline))
			parsed_lines.append(lastline)
			lastline = ''
			continue

	logger.debug(f'Parsed content: {parsed_lines}')
	logger.debug('Parsing lines into key and vaules...')
	for line in parsed_lines:
		k, v = re.findall(r"([a-zA-Z_]+?)=(.*)", line)[0]
		if k in keys_to_modify:
			v = v.strip('"').strip("'")
		# Optionally we can expand variables by using r'\${?([a-zA-Z0-9_]+)}?'.
		# This is not necessary for this script. And calling Bash is more accurate in case of substitution.
		# Or to use pyparser, like what ACBS does.
		logger.debug(f'Splited (k, v) = {(k, v)}')
		kvs[k] = v

	logger.debug(f'Parsed keys and vaules: {kvs}')

	return kvs


def parse_src_kvs(val: str) -> list[dict]:
	'''
	This function accepts the vaule of `SRCS`, i.e. you can pass an array of SRCS entries.
	'''
	srcs = []
	for entry in re.split(r'\s+', val):
		logger.debug(f'Parsing entry: {entry}')
		name, spec = entry.split('::', 1)
		kv = {}
		if '::' in spec:
			options_str, url = spec.split('::')
			for option in options_str.split(';'):
				k, v = option.split('=')
				kv[k] = v
		else:
			url = spec
		kv['name'] = name
		kv['url'] = url
		logger.debug(f'Parsed (k, v): {kv}')
		srcs.append(kv)
	return srcs


def parse_svn_info(s: str) -> dict:
	res = {}
	for i in s.split('\n'):
		sp = i.split(':')
		if len(sp) != 1 and sp[0] != '':
			k = sp[0].strip()
			v = sp[1].strip()
			res[k] = v
			print(res)
	return res


def git_fetch_head(url: str, ref: str, git_srcs_dir: str) -> str:
	'''
	We need to fetch the latest revision and the nearest tag.
	Returns: (commit, tag)
	'''
	commit = ''
	tag = None
	try:
		url_sha256 = hashlib.sha256(url.encode()).digest().hex()
		repo_path = os.path.join(git_srcs_dir, url_sha256)
		logger.info('Updating Git repository {} for {}...'.format(repo_path, url))
		if not os.path.exists(os.path.join(repo_path, '.git')):
			logger.info('Checking out Git tree {} to path {}...'.format(url, repo_path))
			subprocess.run(
				args=['git', 'clone', '--quiet', '-b', ref, '--depth', '1', url, repo_path],
				stderr=subprocess.DEVNULL,
				stdout=subprocess.DEVNULL,
				check=True
			)
		else:
			subprocess.run(
				args=['git', 'pull', '--ff-only', 'origin', ref],
				check=True,
				cwd=repo_path
			)
		commit = subprocess.run(
			args=['git', 'rev-parse', 'HEAD'],
			stdout=subprocess.PIPE,
			check=True,
			cwd=repo_path
		).stdout.decode().strip()

	except subprocess.CalledProcessError:
		raise Exception(f'Can not check latest commit for ref {url}:{ref}. git-ls-remote exited with failure.')
	except Exception:
		raise Exception(f'Failed to fetch {url}.')
	return commit

def svn_fetch_head(url: str, git_srcs_dir: str) -> str:
	commit = ''
	try:
		url_sha256 = hashlib.sha256(url.encode()).digest().hex()
		repo_path = os.path.join(git_srcs_dir, url_sha256)
		logger.info('Updating SVN repository {} for {}...'.format(repo_path, url))
		if not os.path.exists(os.path.join(repo_path, '.svn')):
			logger.info('Checking out SVN tree {} to path {}...'.format(url, repo_path))
			subprocess.run(
				args=['svn', 'checkout', '--quiet', url, repo_path],
				stderr=subprocess.DEVNULL,
				stdout=subprocess.DEVNULL,
				check=True
			)
		else:
			subprocess.run(
				args=['svn', 'upgrade', '--quiet'],
				check=True,
				cwd=repo_path
			)
			subprocess.run(
				args=['svn', 'update', '--quiet'],
				check=True,
				cwd=repo_path
			)
		s = subprocess.run(
			args=['env', 'LANG=C', 'svn', 'info', '-r', 'HEAD'],
			stdout=subprocess.PIPE,
			check=True,
			cwd=repo_path
		)

		s = s.stdout.decode("utf-8")
		s = parse_svn_info(s)
		print(s)
		s = s['Revision']
		commit = s
		print(commit)
		return commit

	except subprocess.CalledProcessError:
		raise Exception(f'Can not check latest commit for ref {url}:{ref}. git-ls-remote exited with failure.')
	except Exception:
		raise Exception(f'Failed to fetch {url}.')



def check_for_update(parsed_srcs: dict, git_srcs_dir: str) -> int:
	logger.info('Checking for updates of all Git sources...')
	count = 0
	for src in parsed_srcs:
		if src['name'] != 'git' and src['name'] != 'svn':
			continue
		logger.info(f'Checking {src["url"]}...')
		ref = 'master' if 'branch' not in src else src['branch']
		if src['name'] == 'git':
			commit_id = git_fetch_head(src['url'], ref, git_srcs_dir)
		elif src['name'] == 'svn':
			commit_id = svn_fetch_head(src['url'], git_srcs_dir)
		if 'commit' in src and commit_id.startswith(src['commit']):
			logger.info(f'Source {src["url"]} is up to date.')
			continue
		src['commit'] = commit_id
		count += 1
	logger.info(f'{count} Git source(s) have been updated.')
	return count


def main():
	logger.level = logger.INFO
	pwd = os.path.realpath('.')
	if 'SRCREPOS_DIR' in os.environ:
		git_srcs_repos_dir = os.environ['SRCREPOS_DIR']
	else:
		git_srcs_repos_dir = os.path.join(os.environ['HOME'], 'srcrepos')
	os.makedirs(git_srcs_repos_dir, exist_ok=True)
	if not os.path.exists(os.path.join(pwd, 'spec')):
		raise FileNotFoundError("spec file does not exist.")
	content = []
	parsed_kvs = {}
	parsed_srcs = []
	with open(os.path.join(pwd, 'spec'), 'r') as f:
		content.extend(l.strip() for l in f.readlines())
	parsed_kvs: dict = parse_kvs(content)
	parsed_srcs = parse_src_kvs(parsed_kvs['SRCS'])
	count = check_for_update(parsed_srcs, git_srcs_repos_dir)
	if count == 0:
		logger.warn('No updates found. Bye!')
		sys.exit(0)
	# Write back changes
	date = datetime.datetime.now().strftime('%Y%m%d')
	ver = parsed_kvs['VER']
	new_ver = f'{ver}+git{date}'
	parsed_kvs['VER'] = new_ver
	logger.info("Writting back changes...")
	constructed_srcs_values= []
	for src in parsed_srcs:
		if len(src) == 2:
			entry = f'{src["name"]}::{src["url"]}'
		else:
			keys = list(src.keys())
			keys.remove('url')
			keys.remove('name')
			option_str = ';'.join(f"{k}={src[k]}" for k in keys)
			entry = f'{src["name"]}::{option_str}::{src["url"]}'
		constructed_srcs_values.append(entry)
	constructed_srcs = ' \\\n\t'.join(constructed_srcs_values)
	parsed_kvs['SRCS'] = constructed_srcs
	with open(os.path.join(pwd, 'spec'), 'w') as f:
		for key in parsed_kvs:
			if key in keys_to_skip:
				continue
			if key in keys_to_modify:
				f.write('{}="{}"\n'.format(key, parsed_kvs[key]))
			else:
				# Replace \n with \\\n + number of whitespaces.
				expanded_val = parsed_kvs[key].replace('\n','\\\n')
				f.write('{}={}\n'.format(key, expanded_val))
		f.write('\n')
	logger.info("Done writting changes. Have fun!")
	sys.exit(0)


if __name__ == '__main__':
	main()
